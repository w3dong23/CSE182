{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1\n",
    "# Goal: Reading the CSV File, Find ecDNA in the CSV File => list of cycle files name\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "# Variables\n",
    "filePath = \"~/Downloads/results/\"\n",
    "fileName = \"aggregated_results.csv\"\n",
    "suffixOfCycleFileName = \"_annotated_cycles.txt\"\n",
    "cycleFileNames = set()\n",
    "\n",
    "# Filters rows that have the classification 'ecDNA'\n",
    "dataTable = pd.read_csv(filePath + fileName)\n",
    "dataTable = dataTable[dataTable['Classification'].notna()]\n",
    "dataTable = dataTable[dataTable['Classification'].str.contains('ecDNA')]\n",
    "\n",
    "dataTable = dataTable['Feature ID']\n",
    "\n",
    "# Makes a list of cycle file names\n",
    "for id in dataTable:\n",
    "    index = id.index('amplicon')\n",
    "    cycleFileNames.add(id[:index+9] + suffixOfCycleFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2\n",
    "# Goal: Open the Feature ID under cycles.txt file, find the cycles in corresponding cycles.txt file \n",
    "# => file with segments & only actual cycle content\n",
    "\n",
    "segment_list = []\n",
    "\n",
    "for file_name in cycleFileNames:\n",
    "    sample_name = file_name.split('_')[0]\n",
    "    path = f'../Downloads/results/AA_outputs/{sample_name}/{sample_name}_classification/{sample_name}_annotated_cycles_files/{file_name}'\n",
    "\n",
    "    with open(path) as file:\n",
    "\n",
    "        # skip lines until cycle info \n",
    "        file.readline() # skip title \n",
    "        line = file.readline()\n",
    "        while line[0] == 'S':\n",
    "            line = file.readline()\n",
    "        \n",
    "        # find segments for cycles\n",
    "        segments = set()\n",
    "        while line:\n",
    "            sep_line = line.split(';')\n",
    "            cyclic = sep_line[3]\n",
    "            cyclic_bool = cyclic.split('=')[1]\n",
    "            if cyclic_bool == 'True':\n",
    "                cycle_segments = sep_line[-1].split('=')[1]\n",
    "                cycle_segments = cycle_segments.split(',')\n",
    "                for i in range(len(cycle_segments)):\n",
    "                    cycle_segments[i] = cycle_segments[i].strip('+-\\n')\n",
    "                for seg in cycle_segments:\n",
    "                    segments.add(seg)\n",
    "            line = file.readline()\n",
    "\n",
    "        # identify chr positions for cyclic segments \n",
    "        file.seek(0)\n",
    "        file.readline() # skip title\n",
    "        line = file.readline()\n",
    "        while line[0] == 'S':\n",
    "            sep_line = line.strip().split('\\t')\n",
    "            new_line = sample_name + ',' + sep_line[2] + ',' + sep_line[3] + ',' + sep_line[4]\n",
    "            if (sep_line[1] in segments) and (new_line not in segment_list):\n",
    "                segment_list.append(new_line)\n",
    "            line = file.readline()   \n",
    "\n",
    "# remove repetitions\n",
    "df = pd.DataFrame(columns=['sample', 'chr', 'start_pos', 'end_pos'])\n",
    "for i in segment_list:\n",
    "    sep_line = i.split(',')\n",
    "    df.loc[len(df.index)] = [sep_line[0], sep_line[1], sep_line[2], sep_line[3]]\n",
    "df.to_csv('cyclic-segments1.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3\n",
    "# Goal: Check each segment to see if they are less than 1000 base pairs => file with chromosome coordinates (no repetitions)\n",
    "\n",
    "samples = []\n",
    "chromnum = []\n",
    "startingcoord = []\n",
    "endingcoord = []\n",
    "\n",
    "with open ('cyclic-segments.tsv') as file:\n",
    "    file.readline() # skip header\n",
    "    for line in file:\n",
    "        l = line.strip()\n",
    "        t = l.split('\\t')\n",
    "        samples.append(t[0])\n",
    "        chromnum.append(t[1])\n",
    "        startingcoord.append(int(t[2]))\n",
    "        endingcoord.append(int(t[3]))\n",
    "\n",
    "df = pd.DataFrame(columns=['sample', 'chr', 'start_pos', 'end_pos'])\n",
    "for i in range(len(startingcoord)):\n",
    "    if ((endingcoord[i]-startingcoord[i]) < 1000):\n",
    "        df.loc[len(df.index)] = [samples[i], chromnum[i], startingcoord[i], endingcoord[i]]\n",
    "df.to_csv('slivers.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4\n",
    "# Goal: \n",
    "\n",
    "# this function will return DNA sequence based on the marker file\n",
    "# marker file format example: Chr7 1 9\n",
    "def findSliverSeq(marker_file):\n",
    "    markers = open(marker_file).readlines()\n",
    "    result_seqs = []\n",
    "\n",
    "    # record information about sliver seq to write to csv file later \n",
    "    samples = []\n",
    "    chr_header = []\n",
    "    start_pos = []\n",
    "    end_pos = []\n",
    "\n",
    "    # load genome\n",
    "    chr2seq = pd.read_pickle('hg38.fa.chr2seq.pydict.pickle')\n",
    "\n",
    "    for marker in markers:\n",
    "        marker_list = marker.strip().split('\\t')\n",
    "\n",
    "        # record info on input file to output to df later\n",
    "        samples.append(marker_list[0])\n",
    "        chr_header.append(marker_list[1])\n",
    "        start_pos.append(int(marker_list[2]))\n",
    "        end_pos.append(int(marker_list[3]))\n",
    "\n",
    "        # find actual sliver sequences \n",
    "        chr_num = marker_list[1]\n",
    "        start = int(marker_list[2])\n",
    "        end = int(marker_list[3])\n",
    "\n",
    "        # extract sequence\n",
    "        seq = chr2seq[chr_num][start:end]\n",
    "        result_seqs.append(seq)\n",
    "\n",
    "    # append all result sequences to a text file line by line \n",
    "    # format like: \n",
    "    # ACTCTCTC\n",
    "    # AACTTTTCCCC\n",
    "    output = ''\n",
    "    for sliver_seq in result_seqs:\n",
    "        output = output + sliver_seq + '\\n'\n",
    "    \n",
    "    # open result file and write to result file with all sliver seuqneces \n",
    "    with open('sliver_sequences.txt', 'w') as result_file:\n",
    "        result_file.write(output)\n",
    "    result_file.close()\n",
    "\n",
    "    # open a csv file for storing all info about sliver sequence found \n",
    "    # cotains chromosome pos and actual sliver sequnce \n",
    "    df = pd.DataFrame()\n",
    "    df['Sample'] = samples\n",
    "    df['Chromosome Position'] = chr_header\n",
    "    df['Start Position'] = start_pos\n",
    "    df['End Position'] = end_pos\n",
    "    df['Sequence'] = result_seqs\n",
    "    df.to_csv('final_slivers.tsv', sep='\\t', index=False)\n",
    "\n",
    "#uncomment to download genome files *YOU ONLY NEED TO DO IT ONCE*\n",
    "# downloadGenome() # ONCE YOU FINISH, COMMENT IT OUT\n",
    "\n",
    "# used to test functions \n",
    "#findSliverSeq('test/example.txt')\n",
    "#findSliverSeq('test/ex2.txt')\n",
    "\n",
    "findSliverSeq('slivers.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
